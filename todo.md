## Goals
The goal of this package is to facilitate the interpretation and quality control of low-dimensional latent spaces generated by dimensionality reduction methods, using heterogeneous input feature types (e.g. numerical as well as image-based inputs). 

## Features
### Quality control
- *Distribution checks* #MEDIUM: Visualize the distributions of the obtained latent dimensions and check if normalization is needed for downstream analysis. 
- *Robustness checks* #HIGH/MEDIUM: 
	- Assess the variability of the obtained encoding for perturbations in the input features
	- Assess how perturbations in latent space affect generated outputs (e.g. class predictions, input reconstruction)
- *Correlation structure* #HIGH: Compute the cross-correlation between latent dimensions
- *Clustering metrics* #LOW: Assess how well defined the obtained clusterings are by computing clustering metrics such as the Silhouette scores and/or the Jaccard Index. 
- *Local neighbourhood preservation* #LOW: Assess how the low-dimensional latent space preserves the local data neighbourhoods in the original input data.
### Interpretation
- *Input feature importance* #HIGH:
	- Which input features vary the most with each latent dimension
	- If prior data is available sets of input features (e.g. pathways/genesets) assess which latent dimensions capture variability in these feature sets
- *Metadata predictive ability* #MEDIUM: 
	- Prediction performance of each latent dimension to predict a metadata variable
		- Simple linear classifier (e.g. logistic/linear regression)
	- Prediction performance of the complete latent space (i.e. multivariate predictors) to predict a metadata variable
		- Random forest feature importance scores to score the laten dimensions
- *Clustering* #MEDIUM:
	- Compute clusterings on the latent space
	- Determine differential input features between different clusters 

*Other feature ideas*:
- Latent space comparisons (Too big of a problem)
- Visualization
	- Static 
	- Interactive
- Pseudotime trajectory for images
## Design
- Python
- PyTorch
- Github
	- Codename: TBA
### Input
- Input training data
	- csv.gz matrix
	- Scanpy
- Model
	- PyTorch model 
- Latent space
	- observations x features
	- numpy matrix
- Metadata
	- observations x metadata variables
	- dataframe
### Output
- Example notebook
### Documentation
- Numpy docstrings

## Example data
- 2 folders:
	- Subcellular expression patterns
	- Multimodal prostate cancer dataset

## Work plan
- David: Boilerplate code:
	- Data loading 
	- Github structure
- Nacho: 
	- Input feature variance per latent dimension 
- Gabriele: 
	- Distribution check of the latent dimensions
- Ceyhun: 
	- Which clusters are variable in which latent dimensions
	- Differential features between clusters
